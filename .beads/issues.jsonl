{"id":"awesome-talon-81y","title":"Talon Command Discovery Engine","description":"## Talon Command Discovery Engine\n\nCrawl 302+ tracked Talon repos, parse .talon files, index voice commands, and surface alternative spoken phrases across repos. Spiritual successor to archived Stolen Sugar project.\n\n### Architecture\n- **Offline pipeline** (Python): Crawl repos -\u003e parse .talon files -\u003e build commands index JSON\n- **Website page** (Next.js /commands): Static page consuming pre-built JSON, client-side search/filter only\n- **CI integration**: Weekly GitHub Action alongside existing enrich.py\n\n### Design Principles\n- All heavy work done async in CI -- the page only reads indexed JSON\n- Follow existing patterns: Python enrichment script -\u003e JSON in website/data/ -\u003e Next.js static page\n- Incremental crawling via pushed_at + blob SHA caching\n\n### References\n- https://github.com/stolen-sugar/stolen-sugar (archived, lessons learned)\n- https://github.com/wenkokke/tree-sitter-talon (formal grammar)\n- https://talon.wiki/Customization/basic_customization/","status":"open","priority":2,"issue_type":"epic","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:22:41.068969139-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:22:41.068969139-08:00"}
{"id":"awesome-talon-81y.1","title":"Step 1: Python crawler — fetch .talon file trees from GitHub API","description":"Write a Python script (scripts/crawl_talon_files.py) that:\n1. Reads repos_full.json for the list of repos to crawl\n2. For each repo, calls GitHub Trees API (GET /repos/{owner}/{repo}/git/trees/{branch}?recursive=1) to list all files\n3. Filters for .talon files\n4. Fetches file content via Blobs API (GET /repos/{owner}/{repo}/git/blobs/{sha})\n5. Caches fetched content by blob SHA in a local cache dir (content-addressable)\n6. Supports incremental mode: skip repos not pushed since last run (compare pushed_at to last crawl timestamp)\n7. Outputs raw .talon content to talon_files_raw.json -- array of {repo, path, sha, content, context_header}\n\nScripts live in top-level scripts/ directory (new directory, not .playground or .github/scripts).\n\n## Verify\n- [ ] Script runs without errors against live GitHub API\n- [ ] Produces talon_files_raw.json with entries from at least 50 repos\n- [ ] Incremental mode skips unchanged repos on second run\n- [ ] Respects GitHub API rate limits (5,000/hr)\n- [ ] Cache directory stores files by blob SHA, reused across runs","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:22:53.320455944-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:27:40.19890673-08:00","dependencies":[{"issue_id":"awesome-talon-81y.1","depends_on_id":"awesome-talon-81y","type":"parent-child","created_at":"2026-02-17T13:22:53.325364062-08:00","created_by":"Trillium Smith"}]}
{"id":"awesome-talon-81y.10","title":"Step 10: Seed data — run initial crawl and commit commands_index.json","description":"Run the full pipeline and seed the repo with initial data:\n1. Run the full pipeline locally to generate the first commands_index.json\n2. Validate the output: check file size, command count, parse success rate\n3. Commit commands_index.json to website/data/ so the site builds without CI\n4. Document any issues found during the initial crawl (update epic if needed)\n5. Verify the website builds and /commands page renders with real data\n\n## Verify\n- [ ] commands_index.json exists in website/data/ and is committed\n- [ ] File size is reasonable (under 10MB)\n- [ ] next build succeeds with the seeded data\n- [ ] /commands page renders with real commands from the ecosystem\n- [ ] At least 50 repos contributed commands to the index\n- [ ] Stats numbers match expectations from the research (8-10K files, 100K+ commands)","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:24:09.802987368-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:24:09.802987368-08:00","dependencies":[{"issue_id":"awesome-talon-81y.10","depends_on_id":"awesome-talon-81y","type":"parent-child","created_at":"2026-02-17T13:24:09.805433481-08:00","created_by":"Trillium Smith"}]}
{"id":"awesome-talon-81y.2","title":"Step 2: .talon file parser — extract voice commands","description":"Write a Python module (scripts/parse_talon.py) that:\n1. Parses .talon file format: context header (above - separator) + command rules (below)\n2. Extracts each command as {spoken_rule, action_body, context}\n3. Handles rule syntax: alternatives (a|b), optionals [word], captures \u003cuser.text\u003e, lists {user.list}\n4. Normalizes context headers (e.g. os: mac, tag: user.cursorless, app: vscode)\n5. Start with regex parsing (handles ~95% of files)\n6. Gracefully skip unparseable files, log warnings\n\n## Verify\n- [ ] Correctly parses talonhub/community .talon files (218 files, ~2500 commands)\n- [ ] Unit tests cover: basic commands, multi-line actions, context headers, rule syntax variants\n- [ ] Parse success rate \u003e= 90% across full corpus\n- [ ] Unparseable files logged but do not crash the script","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:23:04.625958228-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:23:04.625958228-08:00","dependencies":[{"issue_id":"awesome-talon-81y.2","depends_on_id":"awesome-talon-81y","type":"parent-child","created_at":"2026-02-17T13:23:04.636152147-08:00","created_by":"Trillium Smith"}]}
{"id":"awesome-talon-81y.3","title":"Step 3: Command indexer — group by action, find alternatives","description":"Write a Python module (scripts/index_commands.py) that:\n1. Reads parsed commands from step 2\n2. Groups commands by normalized action body to find alternative spoken forms across repos\n3. Identifies the canonical form from talonhub/community (the entry point for most users, fine to treat as canonical)\n4. Deduplicates commands copied verbatim from community (same blob SHA or identical content)\n5. Computes stats: total unique commands, repos with most custom commands, most-overridden commands\n6. Marks commands as \"unique\" when they appear in only 1-2 repos and are NOT from talonhub/community — these are novel/creative commands someone invented\n\n## TWO output artifacts (required by hybrid frontend architecture):\n\n### commands-summary.json (lightweight, for search + list display)\n- Array of {id, rule, context, repoSlug, isCanonical, isUnique, repoCount} for ALL commands\n- isUnique: true when this action exists in only 1-2 repos and is not a community command\n- repoCount: how many repos define this action (enables sorting by \"most common\" or \"most unique\")\n- Target: ~5-10 MB raw, ~1-2 MB gzipped\n\n### commands-detail-{chunk}.json (chunked, for expand/drill-down)\n- Chunked by first letter of spoken rule (a.json, b.json, ... misc.json)\n- Each chunk contains: {id, actionBody, alternatives: [{rule, repo, context, path}], filePath}\n- Each chunk target: ~200-500 KB\n\n### commands-stats.json (small metadata)\n- {total_commands, total_repos_with_talon, total_files_parsed, total_unique_actions, total_unique_commands, most_overridden_commands: [{action, count}], most_creative_repos: [{repo, unique_count}], generated_at}\n\n## Verify\n- [ ] All three artifact types are produced and valid JSON\n- [ ] Summary file is under 3MB gzipped\n- [ ] Detail chunks exist for each letter with commands\n- [ ] Canonical vs alternative distinction works (community commands marked isCanonical)\n- [ ] Unique commands correctly identified (appear in 1-2 repos, not community)\n- [ ] repoCount is accurate for each command group\n- [ ] Stats include most_overridden and most_creative_repos leaderboards\n- [ ] IDs are consistent between summary and detail files (can join them)","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:23:18.113335297-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:53:45.783488761-08:00","dependencies":[{"issue_id":"awesome-talon-81y.3","depends_on_id":"awesome-talon-81y","type":"parent-child","created_at":"2026-02-17T13:23:18.12392396-08:00","created_by":"Trillium Smith"}]}
{"id":"awesome-talon-81y.4","title":"Step 4: Pipeline orchestrator — single entry point for CI","description":"Write a main script (scripts/build_commands_index.py) that:\n1. Orchestrates steps 1-3 in sequence: crawl -\u003e parse -\u003e index\n2. Accepts CLI flags: --full (ignore cache, recrawl everything), --repos-file (path to repos_full.json)\n3. Writes outputs to website/:\n   - website/data/commands-stats.json (read at build time by server component)\n   - website/public/data/commands-summary.json (fetched at runtime by client)\n   - website/public/data/commands-detail-{a-z,misc}.json (fetched on demand)\n4. Prints summary to stdout (total repos crawled, files parsed, commands indexed, errors)\n5. Exits with nonzero code on critical failure (e.g. no GitHub token, API down)\n6. Handles GITHUB_TOKEN from environment (same pattern as existing enrich.py)\n7. Uses only stdlib (no pip install needed — match existing script conventions)\n\nScripts live in top-level scripts/ directory.\n\n## Verify\n- [ ] Running the script end-to-end produces all output files\n- [ ] Summary output is printed to stdout\n- [ ] --full flag forces complete recrawl\n- [ ] Script fails gracefully with clear error if GITHUB_TOKEN is missing\n- [ ] Exit code is 0 on success, nonzero on failure\n- [ ] Output files are valid JSON and correctly split (summary vs detail vs stats)","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:23:29.197267677-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:36:02.350995397-08:00","dependencies":[{"issue_id":"awesome-talon-81y.4","depends_on_id":"awesome-talon-81y","type":"parent-child","created_at":"2026-02-17T13:23:29.210082641-08:00","created_by":"Trillium Smith"}]}
{"id":"awesome-talon-81y.5","title":"Step 5: GitHub Action — weekly CI for command index","description":"The command index should be generated by a GitHub Action that runs periodically and commits the result back to the repo (same pattern as enrich-dates.yml, NOT embedded in the deploy workflow).\n\nCreate .github/workflows/crawl-commands.yml:\n1. Runs on a weekly schedule (Monday 6am UTC) + manual workflow_dispatch trigger\n2. Work is performed in batches — the crawler processes repos in batches to stay within API rate limits\n3. Steps: checkout -\u003e setup Python -\u003e run scripts/build_commands_index.py -\u003e verify output -\u003e commit + push\n4. On completion, commits commands_index.json back to the repo (like enrich_dates.py auto-commits resource_dates.json)\n5. GITHUB_TOKEN provided via secrets.GITHUB_TOKEN\n6. Cache the blob SHA cache directory between CI runs (actions/cache) for incremental crawling\n7. The deploy-website.yml workflow picks up the committed commands_index.json on next deploy — no coupling between workflows\n\n## Verification is built into the workflow\n- Verify commands_index.json is valid JSON before committing\n- Verify file size is under 10MB\n- Verify command count is nonzero\n- Log a summary: repos crawled, files parsed, commands indexed, errors\n- Only commit if the file actually changed (diff check like enrich-dates.yml)\n\n## Verify\n- [ ] Workflow runs successfully via manual trigger\n- [ ] commands_index.json is committed back to the repo automatically\n- [ ] Cache persists between runs (incremental crawling works)\n- [ ] Workflow completes within GitHub Actions time limits\n- [ ] deploy-website.yml still works independently (picks up committed data)\n- [ ] Bad data is never committed (validation gate prevents corrupt output)","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:23:39.306544122-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:34:56.367378338-08:00","dependencies":[{"issue_id":"awesome-talon-81y.5","depends_on_id":"awesome-talon-81y","type":"parent-child","created_at":"2026-02-17T13:23:39.319864768-08:00","created_by":"Trillium Smith"}]}
{"id":"awesome-talon-81y.6","title":"Step 6: Data loader — load-commands.ts library module","description":"Create website/src/lib/load-commands.ts following existing patterns (load-repos.ts, load-resource-dates.ts):\n\n## Server-side (build time)\n1. Reads commands-stats.json at build time for the page shell (stats banner, metadata)\n2. Exports loadCommandStats(): CommandStats\n3. Graceful fallback: returns empty/zero stats if file missing\n\n## Client-side (runtime)\nThe summary and detail files live in public/ and are fetched at runtime, NOT loaded at build time (too large for SSR props).\nThe data loader should export:\n- fetchCommandsSummary(): Promise\u003cCommandSummary[]\u003e — fetches commands-summary.json from public/\n- fetchCommandDetail(letter: string): Promise\u003cCommandDetail[]\u003e — fetches commands-detail-{letter}.json\n\n## Types to export\n- CommandSummary: {id, rule, context, repoSlug, isCanonical}\n- CommandDetail: {id, actionBody, alternatives: CommandAlternative[], filePath}\n- CommandAlternative: {rule, repo, context, path}\n- CommandStats: {total_commands, total_repos_with_talon, total_files_parsed, total_unique_actions, generated_at}\n\n## Verify\n- [ ] Types are well-defined and exported\n- [ ] loadCommandStats() returns typed data at build time\n- [ ] Returns empty/default stats when file is missing (no build crash)\n- [ ] fetchCommandsSummary() and fetchCommandDetail() work client-side\n- [ ] All types align with the Python indexer output schema","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:24:09.424751604-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:35:43.482143475-08:00","dependencies":[{"issue_id":"awesome-talon-81y.6","depends_on_id":"awesome-talon-81y","type":"parent-child","created_at":"2026-02-17T13:24:09.426947621-08:00","created_by":"Trillium Smith"}]}
{"id":"awesome-talon-81y.7","title":"Step 7: /commands page — server component shell","description":"Create website/src/app/commands/page.tsx:\n1. Server component that loads command stats via loadCommandStats() at build time\n2. Does NOT embed the full command data as props (too large for SSR)\n3. Passes only stats to the CommandsExplorer client component, which fetches summary/detail at runtime\n4. Includes page metadata: title \"Voice Commands - Awesome Talon\", description for SEO\n5. Stats banner: total commands, repos with .talon files, files parsed, last updated\n6. Graceful empty state if commands-stats.json is missing or has zero counts\n\n## Verify\n- [ ] Page renders at /commands without errors\n- [ ] Stats banner shows accurate numbers from commands-stats.json\n- [ ] Empty state renders cleanly when no data is available\n- [ ] Page metadata is correct\n- [ ] next build succeeds with the new page (even without summary/detail files in public/)\n- [ ] The page does NOT bloat the static HTML (data fetched client-side)","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:24:09.51063441-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:36:02.497453518-08:00","dependencies":[{"issue_id":"awesome-talon-81y.7","depends_on_id":"awesome-talon-81y","type":"parent-child","created_at":"2026-02-17T13:24:09.512648985-08:00","created_by":"Trillium Smith"}]}
{"id":"awesome-talon-81y.8","title":"Step 8: CommandsExplorer — client component with search and filtering","description":"Create website/src/components/CommandsExplorer.tsx (client component).\n\n## Architecture: Hybrid Summary + Detail Loading\nThe page does NOT load the full dataset at once. Instead:\n1. On page load, fetch commands-summary.json (~1-2 MB gzipped) containing {id, rule, context, repoSlug, isCanonical, isUnique, repoCount} for all commands\n2. Build a MiniSearch index in-memory from summary data (~1-2s, show loading skeleton)\n3. Render results using TanStack Virtual (@tanstack/react-virtual) — only ~30 DOM nodes regardless of result count\n4. When user expands a command, fetch the detail chunk for full action body + alternatives\n\n## Dependencies to add\n- minisearch (~7KB gzip) — client-side full-text search\n- @tanstack/react-virtual (~12KB gzip) — virtualized rendering\n\n## UI Design (follows EcosystemFilter patterns)\nPrimary filters (always visible):\n- Search input: searches command voice pattern, action, context, AND repo name. Placeholder: \"Search commands, contexts, repos...\"\n- Context dropdown: \u003cselect\u003e with common contexts (All, VS Code, Browser, Terminal, Mac, Linux, Windows)\n\nSecondary filters:\n- Sort dropdown: Most alternatives, Alphabetical, Most unique\n- Checkbox: Hide duplicates / Show unique only\n- Checkbox: Show unique commands only (isUnique — commands in 1-2 repos, not from community)\n\nUnique commands get a visual badge/indicator (e.g. a \"Unique\" or \"Novel\" chip) so users can spot creative commands while browsing.\n\nCommand cards show:\n- Canonical spoken rule (highlighted, from talonhub/community)\n- Action body (code-formatted, loaded on expand)\n- Repo badge chip — clicking it applies repo:owner/name to search box\n- \"in N repos\" count badge, expandable to show alternatives\n- \"Unique\" badge when isUnique is true\n\n## Search qualifier syntax (progressive enhancement)\n- repo:talonhub/community — filter to a single repo\n- app:vscode — filter to VS Code context\n- os:mac — filter to Mac OS\n- Free text searches command patterns and descriptions\n\n## What NOT to build for v1\n- No searchable combobox for repos (text search handles it)\n- No faceted sidebar\n- No tag chips for multi-repo selection\n- No \"link my repo\" personalized view (Version B — follow-up ticket)\n\n## Build-time data pipeline (scripts/ responsibility)\nThe Python pipeline must produce TWO artifacts:\n1. commands-summary.json — lightweight, all records, searchable fields only + isUnique + repoCount\n2. commands-detail-{chunk}.json — chunked by letter/category, full record data\n\n## Verify\n- [ ] Loading skeleton shown while summary fetches + index builds\n- [ ] Search filters commands in real-time without lag (sub-millisecond via MiniSearch)\n- [ ] Context dropdown filters correctly\n- [ ] Sort options reorder results as expected\n- [ ] \"Show unique only\" filter works and surfaces novel community commands\n- [ ] Unique badge displays on commands in 1-2 repos\n- [ ] Virtual scrolling works — scrolling 100K results stays smooth (60fps)\n- [ ] Command expand loads detail chunk and shows action body + alternatives\n- [ ] repo:slug search qualifier works\n- [ ] Dark mode renders correctly\n- [ ] Total initial payload is under 3MB gzipped","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:24:09.585016718-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:54:11.922656255-08:00","dependencies":[{"issue_id":"awesome-talon-81y.8","depends_on_id":"awesome-talon-81y","type":"parent-child","created_at":"2026-02-17T13:24:09.587084486-08:00","created_by":"Trillium Smith"}]}
{"id":"awesome-talon-81y.9","title":"Step 9: Navigation — add Commands link to site nav","description":"Update site navigation:\n1. Add Commands link to the site navigation/header alongside existing pages\n2. Add a Commands section or link to the home page (similar to how Ecosystem and Curated List are linked)\n3. Update home page stats if relevant (e.g. add a Voice commands indexed stat)\n\n## Verify\n- [ ] Commands link appears in site navigation\n- [ ] Link navigates to /commands correctly\n- [ ] Active state works when on /commands page\n- [ ] Home page references the commands feature\n- [ ] All existing navigation still works","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:24:09.697368105-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:24:09.697368105-08:00","dependencies":[{"issue_id":"awesome-talon-81y.9","depends_on_id":"awesome-talon-81y","type":"parent-child","created_at":"2026-02-17T13:24:09.700514039-08:00","created_by":"Trillium Smith"}]}
{"id":"awesome-talon-cf4","title":"Compile common voice dictation word replacements list","description":"Build a reference list of words commonly misrecognized or replaced in voice dictation with Talon.\n\nKey discovery: talonhub/community has a built-in system for this:\n- settings/words_to_replace.csv — CSV file (auto-created on first run) where users map misrecognized words to correct ones. Format: target word first, spoken/misheard word second.\n- core/vocabulary/vocabulary.py — PhraseReplacer class that powers the substitution system. Also handles capitalization defaults (months, etc.) and custom vocabulary.\n- Users can add replacements by voice: 'copy to replacements as \u003cphrase\u003e' (edit_vocabulary.talon)\n- The file is per-user (in settings/ dir, gitignored by most people)\n\nIdea: Aggregate words_to_replace.csv files from:\n1. Notable personal configs in the awesome list (andreas-talon, colton_talon, etc.)\n2. Community Slack discussions about common misrecognitions\n3. The homophones.csv file (core/homophones/homophones.csv)\n\nPossible outputs:\n- A crowdsourced 'common replacements' reference on the website\n- A starter words_to_replace.csv that new users can drop in\n- Searchable dataset showing which words are most commonly confused\n\nExample: 'crash mark' → 'question mark' (speech engine substitution)","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T10:51:49.987228644-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T10:53:36.622744283-08:00"}
